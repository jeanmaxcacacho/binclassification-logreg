---
title: "Supervised Classification of Diabetes Data"
author: Jean Maximus C. Cacacho
format: html
---

# Introduction

The data used to perform this *report(?)* was obtained from an open-access Kaggle data repository. Accessing this data can be done through the link below:

https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset

The primary objective of this study is to perform a **binary classification task with logistic regression**, identifying diabetic from non-diabetic observations. Second to this would be examining the effect of two different resampling approaches: **(i) oversampling with Random Oversampling** and **(ii) undersampling with Random Undersampling**, to the performance of the model.

# Data Pre-processing

To yield a performant model, it's imperative for our input data to be clean. This involves pruning observations from the original data file, scaling values, and the appropriate value conversions, among other appropriate steps that may arise.

On a high level, what is done in this subsection of the *notebook(?)* are the following:

1. Loading the dataset into R studio.
2. Summary statistics informing data cleanup process.
3. Data cleanup.

## Loading Data
In this step the `diabetes_prediction_dataset.csv` file is stored into a dataframe.
```{r}
library(data.table)
raw_df <- fread("../data/diabetes_prediction_dataset.csv")
```
After this, the head and tail of the loaded dataframe was inspected to see if the file was read into the environment.

### Head
```{r}
head(raw_df)
```
### Tail
```{r}
tail(raw_df)
```

## Removing Nulls
Before further pre-processing steps (scaling, value conversion etc.), observations that aren't *complete* will be removed. Essentially rows with missing data are to be discarded from the considered dataset.

### Counting Nulls / Attribute
```{r}
colnames(raw_df)
```
From this cell it can be gathered that there are 9 attributes all in all. From the whole dataset with respect to each of these attributes, we count the amount of nulls.
```{r}
null_counts <- raw_df[, lapply(.SD, function(x) sum(is.na(x) | trimws(x) == ""))]
print(null_counts)
```
The result of the previous cell shows that all rows have complete data.

## Value Conversions
Part of data pre-processing is also ensuring that observations are stored in programmatically convenient formats. In the context of R an example of this would be storing categorical/discrete data as `factor`s.

`str(raw_df)` can be used to inspect how these values are stored in the dataframe.
```{r}
str(raw_df)
```
The previous query showed that the following attributes: (i) gender, (ii) hypertension, (iii) heart_disease, (iv) smoking_history, and (v) diabetes, are categorical. However, the attribute smoking_history seems to have more than just 2 possible values.

To be sure, an inspection of all unique values in these attributes ascertains whether or not the value is binary or not.
```{r}
categorical_attr <- c("gender", "hypertension", "heart_disease", "smoking_history", "diabetes")

unique_vals <- lapply(raw_df[, ..categorical_attr], unique)
print(unique_vals)
```
It can be seen that the attributes: hypertension, heart_disease, and diabetes, already only have two possible values; gender and smoking_history however do not.

### Handling `gender` Attribute
*Surface level research* shows that individuals with non-binary gender identities show higher incidence rates for other diabetes related comorbidities, e.g. smoking [(Tan et. al. 2021)](https://pmc.ncbi.nlm.nih.gov/articles/PMC8529476/#:~:text=Transgender%20and%20gender%2Dexpansive%20(TGE)%20adults%E2%80%94individuals%20who%20have,to%20smoke%20cigarettes%20than%20cisgender%20individuals%20[3].). This suggests that gender identities beyond just male and female may provide the model with sufficient information, along with other features, for classification.

| gender | description                          | encoding |
|------------------|--------------------------------------|----------:|
| Male            | Individual whose sex is Male                  |         0 |
| Female           | Individual whose sex is Female                  |         1 |
| Other      | Individual with non-binary gender identity       |         2 |

These encodings serve only to be labels that are programmatically convenient to work with in processing.
```{r}
gender_encodings = c(
  "Male" = 0,
  "Female" = 1,
  "Other" = 2
)

raw_df[, gender_code := gender_encodings[gender]]
print(raw_df)
```
It can be seen that `gender` has been successfully encoded into `gender_code`. As such, the original column can now be discarded.
```{r}
raw_df[, gender := NULL]
print(raw_df)
```
### Handling `smoking_history` Attribute
The earlier cell that was supposed to detect and count for null values was not able to catch `smoking_history` observations marked with `No Info`. That was because the previous function looked for values stored in R as `NA` or as empty strings. Including these observations may just be *noise* for the classifier, as such observations with `No Info` in `smoking_history` are discarded.
```{r}
row_count_before <- raw_df[, .N] # row count before drop
print(paste("Row count before drop: ", row_count_before))

raw_df <- raw_df[!(smoking_history == "No Info")]

unique(raw_df$smoking_history)
row_count_after <- raw_df[, .N] # row count after drop
print(paste("Row count after drop: ", row_count_after))
```
To turn the remaining string values into meaningful numerical data, **ordinal encoding comes to mind.** Notice how the magnitude of `smoking_history` can be surmised from the current values; those who have never smoked have, by definition, smoked less than those who were former smokers. Through the same intuition, it can be said that current smokers smoke the most. Formal definitions for these terms can be obtained from [online medical sources](https://www.cdc.gov/mmwr/volumes/72/wr/mm7210a7.htm).

From this information these encodings were generated:

| smoking_history | description                          | encoding |
|------------------|--------------------------------------|----------:|
| never            | never smoked before, or has smoked less than 100 cigarettes in their lifetime                  |         0 |
| former           | smoked at least 100 cigarettes in their lifetime but does not currently smoke                  |         1 |
| not current      | smoked at least 100 cigarettes in their lifetime but does not currently smoke       |         1 |
| ever             | term encompassing both current and former smokers, anyone who has smoked at least 100 cigarettes in their lifetime     |         1 |
| current          | smoked at least 100 cigarettes in their lifetime and currently smokes                        |         2 |

It must be noted that in the context of this project, the terms `former`, `ever`, and `not current`, were not defined in the data card. As such, operative definitions were gleaned from the CDC *QuickStats* article hyperlinked above.
```{r}
smoking_encodings <- c(
  "never" = 0,
  "former" = 1,
  "not current" = 1,
  "ever" = 1,
  "current" = 2
)

raw_df[, smoking_code := smoking_encodings[smoking_history]]

print(raw_df)
```
It can be seen that `smoking_history` has been encoded successfully into the column smoking_code; the old column can now be safely discarded.
```{r}
raw_df[, smoking_history := NULL]

print(raw_df)
```
Now that the data is clean, categorical columns can now be converted to the `factor` data type.
```{r}
categorical_attr2 <- c("gender_code", "hypertension", "heart_disease", "smoking_code", "diabetes")

raw_df[, (categorical_attr2) := lapply(.SD, as.factor), .SDcols = categorical_attr2]

# verify changes
str(raw_df)
```

# Exploratory Data Analysis

The goal in exploratory data analysis is discovering correlations and distributions across all attributes. This is important as in this project, it serves as the main guide for feature selection.

Excluding the target, the current cleaned table has 8 attributes of which 4 are categorical (`hypertension`, `heart_disease`, `gender_code`, and `smoking_code`) and the other 4 (`age`, `bmi`, `HbA1c_level`, `blood_glucose_level`) are continuous.

## Analyzing Target Distribution

One of the biggest hurdles in classification tasks is class imbalance in the data; when there are more observations for a certain dependent variable than others then there is a class imbalance. In the context of the project the dependent variable is the `diabetes` attribute.

```{r}
counts <- table(raw_df$diabetes)

barplot(
  counts,
  names.arg = c("Non-diabetic", "Diabetic"),
  col = "steelblue",
  main = "Target Variable Distribution",
  xlab = "Classification",
  ylab = "Observation Frequency")
```

Visually it can be seen that the data is **greatly imbalanced**.

## Examination of Continuous Attributes

For this subsection we consider the continuous attributes of the dataset and how they relate to the target variable.
```{r}
continuous_attr <- c("age", "bmi", "HbA1c_level", "blood_glucose_level")
continuous_attr_histdata <- raw_df[, ..continuous_attr]

par(mfrow = c(2, 2))
for (attr in continuous_attr) {
  hist(continuous_attr_histdata[[attr]],
       main = paste("Histogram of", attr),
       col = "lightblue",
       xlab = attr)
}
```

The correlations of these continuous data attributes is shown in the correlation matrix below:
```{r}
cor_matrix <- cor(continuous_attr_histdata, use = "complete.obs")

print(cor_matrix)
```

Correlation between these variables seem very weak. No strong linear relationship can be made with any of them with each other. Given that EDA serves as the primary guide of feature selection in the project, it can be inferred that these attributes are not linearly redundant. This justifies the inclusion of all of these attributes into the feature set.

## Examination of Categorical Attributes

For this subsection we consider the categorical attributes of the dataset and how they relate to the target variable.
```{r}
categorical_attr3 <- c("hypertension", "heart_disease", "gender_code", "smoking_code")
categorical_attr_notarg <- raw_df[, ..categorical_attr3]

par(mfrow = c(2,2))
for (attr in categorical_attr3) {
  barplot(table(categorical_attr_notarg[[attr]]),
          main = paste("Distribution of", attr),
          col = "lightgreen")
}
```
For an analysis of these attributes the chi-square test for independence can be used to see *correlation* between the attribute and target.
```{r}
categorical_attr_wtarg <- c(categorical_attr3, "diabetes")
categorical_eda <- raw_df[, ..categorical_attr_wtarg]

# Chi-square test: Hypertension v.s. Diabetes
chisq.test(table(categorical_eda$hypertension, categorical_eda$diabetes))

# Chi-square test: Heart Disease v.s. Diabetes
chisq.test(table(categorical_eda$heart_disease, categorical_eda$diabetes))

# Chi-square test: Gender v.s. Diabetes
chisq.test(table(categorical_eda$gender_code, categorical_eda$diabetes))

# Chi-square test: Smoking v.s. Diabetes
chisq.test(table(categorical_eda$smoking_code, categorical_eda$diabetes))
```
All p-values obtained are very small (p < 2.2e-16) which provides strong evidence to reject the null-hypothesis. For the attributes `hypertension`, `heart_disease`, and `smoking_code` this is to be expected since they are known comorbidities for many diseases. However, `gender_code` also yielding low p-values suggests that gender (not sex, since non-binary identites are included) is statistically significant when analyzing diabetes distribution.

All that being said, failure to reject the null hypothesis for any of the variables suggests that they should be included to the final feature set.

# Modeling

From EDA, through the use of correlation matrix and Chi-square tests, the final feature set was obtained. Continuous variables were not colinear with each other and all categorical variables yielded small p-values, as such all nine features from the base dataset is used in modeling.

In this section logistic regression is run three times: (i) without resampling, (ii) resampling with ROS, and (iii) resampling with RUS. The target data distribution is heavily imbalanced, making the dataset a good candidate for analyzing performance contributions/effects of resampling techniques.

## Scaling Continuous Attributes

https://www.geeksforgeeks.org/logistic-regression-and-the-feature-scaling-ensemble/

An inspection of the data's continuous attributes (e.g. `age`, `bmi`, `blood_glucose_level`) makes apparent the difference in *scale* that these values have. From a numerical standpoint, measurements in `bmi` and `age` are significantly less than measurements in `blood_glucose_level`.

Feature scaling ensures that all features contribute equally to the model's learning process. Numerically large features, when not scaled properly, may dominate learning over smaller-scale features; `blood_glucose_level` may, by virtue of the units it's measured in, overtake `HbA1c_level` in contribution because of the difference in their values.

`scale` performs z-score scaling, centering values around 0.
```{r}
raw_df$age <- scale(raw_df$age)
raw_df$bmi <- scale(raw_df$bmi)
raw_df$HbA1c_level <- scale(raw_df$HbA1c_level)
raw_df$blood_glucose_level <- scale(raw_df$blood_glucose_level)

print(raw_df[, ..continuous_attr])
```
## Logistic Regression without Resampling

In this subsection, logistic regression is performed and evaluated for accuracy without resampling.
```{r}
for_baseline <- copy(raw_df)

print(for_baseline)
```
### Train & Test Set Creation
```{r}
# https://rpubs.com/SameerMathur/LR_GLM_CCDefault

set.seed("123")

# there are 60k rows so let's try 80-20
split_baseline <- caTools::sample.split(for_baseline$diabetes, SplitRatio = 0.8)

baseline_train_data <- subset(for_baseline, split_baseline == TRUE)
baseline_test_data <- subset(for_baseline, split_baseline == FALSE)

print(baseline_train_data)
```
### Model Training
```{r}
baseline_model <- glm(diabetes ~ .,
                      data = baseline_train_data,
                      family = binomial)
summary(baseline_model)
```
### Making Predictions on `baseline_test_data`
```{r}
baseline_test_probs <- predict(baseline_model,
                               newdata = baseline_test_data,
                               type = "response")
baseline_test_pred <- ifelse(baseline_test_probs > 0.5, 1, 0)

# report accuracy
mean(baseline_test_pred == baseline_test_data$diabetes)
```
Without any resampling, the probability of an accurate prediction is 94.9%? That's higher than most people's final grade in CSCI 21! Recall that the target distribution is greatly imbalanced, this is may be a case of the *accuracy paradox* where the model correctly makes predictions on the majority class and neglects the minority class.

### Confusion Matrix
```{r}
# https://www.geeksforgeeks.org/confusion-matrix-in-r/

baseline_confmatrix <- caret::confusionMatrix(
  as.factor(baseline_test_data$diabetes),
  as.factor(baseline_test_pred)
)

print(baseline_confmatrix)
```
The confusion matrix sheds more light on the model's performance. For cases where the model is tested on diabetic data (the correct prediction is 1), the model does not perform so well. In the second line of the confusion matrix the ratio between false positives and true positives is 500:909.

PPV and NPV values make more apparent the *accuracy paradox*. The PPV being 98.7% means that when the model makes a 0 prediction (non-diabetic), it is correct 98.7% of the time. In contrast, the NPV being 64.5% means that when the model predicts a 1 prediction (diabetic), it is only correct 64.5% of the time. **Given the class imbalance, the model will still get a high accuracy mark if it just predicted all observations to be non-diabetic.**

## Logistic Regression with Resampling

The previous subsection showed room for improvement with the NPV of the model. One of the main challenges in classification tasks is deciding how to handle class imbalances, one of the ways this is addressed is through resampling. Resampling, makes it so that the proportions in the training data is more balanced, giving the model more exposure to both targets.

The resampling approaches used in this project are: **(i) Oversampling with ROS, and (ii) Undersampling with RUS**. 

### Train & Test Set Creation for ROS
```{r}
for_ROS <- copy(raw_df)

set.seed("123")

split_ROS <- caTools::sample.split(for_ROS$diabetes, SplitRatio = 0.8)

ROS_train_data <- subset(for_ROS, split_ROS == TRUE)
ROS_test_data <- subset(for_ROS, split_ROS == FALSE)

print(ROS_train_data)
```
### ROS Resampling

ROS works by randomly duplicating rows of the minority class, adding these dupes up until both classes have roughly the same number of instances. As such, plotting the training data before and after resampling shows the effect of ROS on the observed class imbalance.

```{r}
ROS_targcounts <- table(ROS_train_data$diabetes)

barplot(
  ROS_targcounts,
  names.arg = c("Non-diabetic", "Diabetic"),
  col = "steelblue",
  main = "Target Variable Distribution Before ROS",
  xlab = "Classification",
  ylab = "Observation Frequency")
```

The distribution in the bar graph mirrors the one shown in EDA previously.
```{r}
print(ROS_targcounts)
```

Getting an approximate ratio...
```{r}
targ_ratio <- 45710 / 5637
targ_ratio
```
The majority class outnumbers the minority class by about 8 to 1. 
```{r}
ROS_output <- ROSE::ovun.sample(
  diabetes ~ .,
  data = ROS_train_data,
  method = "over",
  N = 2*max(table(ROS_train_data$diabetes))
)

ROS_train_data <- ROS_output$data
ROS_train_data
```

The new target distribution is...
```{r}
ROS_targcounts2 <- table(ROS_train_data$diabetes)

barplot(
  ROS_targcounts2,
  names.arg = c("Non-diabetic", "Diabetic"),
  col = "steelblue",
  main = "Target Variable Distribution After ROS",
  xlab = "Classification",
  ylab = "Observation Frequency")
```
### Modeling with RUS